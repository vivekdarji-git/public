{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20200914_mnist nn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMFjG32a5Vl+qy7Qv4InoKb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivekdarji-git/public/blob/master/20200914_mnist_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQHf4ZdquHE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from keras.models import Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvT81eiPvS-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test,y_test) = mnist.load_data()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_as4pbdqwCJy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9bd075c-8e60-4b4a-cc76-acf081083aa2"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFSAaYujwHsY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "672f0cdc-db30-4f0c-f823-018366389c72"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3Oj3dNXwf_q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "042ed41b-c013-4793-906c-21b6b238955a"
      },
      "source": [
        "x_train.shape[0]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dADQTxgOwJOg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a43ff18a-f567-409b-9c6b-8054335f3b18"
      },
      "source": [
        "image_height = 28\n",
        "image_width = 28\n",
        "num_channels = 1\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], image_height, image_width, num_channels)\n",
        "x_test = x_test.reshape(x_test.shape[0], image_height, image_width, num_channels)\n",
        "x_train.shape"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjHORHbOwl-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EYXhQQ5wwUg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "055e7776-62e3-4742-cf5c-841a3ae0cc67"
      },
      "source": [
        "image_size = 28*28\n",
        "num_classes = 10\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#define conv layers\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', padding = 'same', input_shape = (28,28,1)))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu', padding = 'same'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu', padding = 'same'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units = 128, activation= 'relu'))\n",
        "model.add(Dense(units = num_classes, activation = 'softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_16 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 128)               73856     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 130,890\n",
            "Trainable params: 130,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvXKM4lDBvV3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d41cbb61-7f7a-428a-fb8d-63a1eaf926ea"
      },
      "source": [
        "history = model.fit(x_train, y_train, batch_size = 64, epochs = 100, verbose = True, validation_split = 0.2)\n",
        "loss, acc = model.evaluate(x_test, y_test, verbose= True)\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training', 'validation'], loc='best')\n",
        "plt.show()\n",
        "\n",
        "print(f'Test loss: {loss:.3}')\n",
        "print(f'Test accuracy: {accuracy:.3}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0151 - accuracy: 0.9957 - val_loss: 0.0569 - val_accuracy: 0.9871\n",
            "Epoch 2/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.0696 - val_accuracy: 0.9852\n",
            "Epoch 3/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.0540 - val_accuracy: 0.9887\n",
            "Epoch 4/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0160 - accuracy: 0.9955 - val_loss: 0.0508 - val_accuracy: 0.9893\n",
            "Epoch 5/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0162 - accuracy: 0.9956 - val_loss: 0.0617 - val_accuracy: 0.9882\n",
            "Epoch 6/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.0783 - val_accuracy: 0.9883\n",
            "Epoch 7/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.0796 - val_accuracy: 0.9868\n",
            "Epoch 8/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0140 - accuracy: 0.9961 - val_loss: 0.0814 - val_accuracy: 0.9878\n",
            "Epoch 9/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 0.0660 - val_accuracy: 0.9890\n",
            "Epoch 10/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.0786 - val_accuracy: 0.9885\n",
            "Epoch 11/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.0574 - val_accuracy: 0.9899\n",
            "Epoch 12/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.0823 - val_accuracy: 0.9874\n",
            "Epoch 13/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0124 - accuracy: 0.9967 - val_loss: 0.0837 - val_accuracy: 0.9889\n",
            "Epoch 14/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0769 - val_accuracy: 0.9887\n",
            "Epoch 15/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0115 - accuracy: 0.9974 - val_loss: 0.0973 - val_accuracy: 0.9877\n",
            "Epoch 16/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 0.0797 - val_accuracy: 0.9893\n",
            "Epoch 17/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 0.0870 - val_accuracy: 0.9870\n",
            "Epoch 18/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0113 - accuracy: 0.9971 - val_loss: 0.1221 - val_accuracy: 0.9854\n",
            "Epoch 19/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0132 - accuracy: 0.9967 - val_loss: 0.0962 - val_accuracy: 0.9891\n",
            "Epoch 20/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0106 - accuracy: 0.9977 - val_loss: 0.0813 - val_accuracy: 0.9911\n",
            "Epoch 21/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 0.1114 - val_accuracy: 0.9873\n",
            "Epoch 22/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0111 - accuracy: 0.9975 - val_loss: 0.1463 - val_accuracy: 0.9844\n",
            "Epoch 23/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 0.1000 - val_accuracy: 0.9896\n",
            "Epoch 24/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.1015 - val_accuracy: 0.9884\n",
            "Epoch 25/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0113 - accuracy: 0.9977 - val_loss: 0.0824 - val_accuracy: 0.9890\n",
            "Epoch 26/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 0.0927 - val_accuracy: 0.9893\n",
            "Epoch 27/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0123 - accuracy: 0.9977 - val_loss: 0.1407 - val_accuracy: 0.9864\n",
            "Epoch 28/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0115 - accuracy: 0.9976 - val_loss: 0.0960 - val_accuracy: 0.9883\n",
            "Epoch 29/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0084 - accuracy: 0.9980 - val_loss: 0.1285 - val_accuracy: 0.9881\n",
            "Epoch 30/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0101 - accuracy: 0.9983 - val_loss: 0.0753 - val_accuracy: 0.9908\n",
            "Epoch 31/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.1176 - val_accuracy: 0.9873\n",
            "Epoch 32/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0110 - accuracy: 0.9977 - val_loss: 0.1310 - val_accuracy: 0.9878\n",
            "Epoch 33/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0111 - accuracy: 0.9979 - val_loss: 0.1389 - val_accuracy: 0.9868\n",
            "Epoch 34/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0099 - accuracy: 0.9982 - val_loss: 0.1038 - val_accuracy: 0.9896\n",
            "Epoch 35/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0094 - accuracy: 0.9983 - val_loss: 0.1378 - val_accuracy: 0.9873\n",
            "Epoch 36/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0092 - accuracy: 0.9984 - val_loss: 0.1258 - val_accuracy: 0.9884\n",
            "Epoch 37/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0110 - accuracy: 0.9981 - val_loss: 0.1422 - val_accuracy: 0.9867\n",
            "Epoch 38/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0148 - accuracy: 0.9974 - val_loss: 0.1275 - val_accuracy: 0.9868\n",
            "Epoch 39/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.1412 - val_accuracy: 0.9904\n",
            "Epoch 40/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0078 - accuracy: 0.9985 - val_loss: 0.1499 - val_accuracy: 0.9883\n",
            "Epoch 41/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0191 - accuracy: 0.9970 - val_loss: 0.1358 - val_accuracy: 0.9892\n",
            "Epoch 42/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.1341 - val_accuracy: 0.9900\n",
            "Epoch 43/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0071 - accuracy: 0.9988 - val_loss: 0.1735 - val_accuracy: 0.9887\n",
            "Epoch 44/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0081 - accuracy: 0.9986 - val_loss: 0.1444 - val_accuracy: 0.9890\n",
            "Epoch 45/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0149 - accuracy: 0.9976 - val_loss: 0.1711 - val_accuracy: 0.9877\n",
            "Epoch 46/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0094 - accuracy: 0.9984 - val_loss: 0.1465 - val_accuracy: 0.9905\n",
            "Epoch 47/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0104 - accuracy: 0.9987 - val_loss: 0.1823 - val_accuracy: 0.9870\n",
            "Epoch 48/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0117 - accuracy: 0.9980 - val_loss: 0.1970 - val_accuracy: 0.9873\n",
            "Epoch 49/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0166 - accuracy: 0.9979 - val_loss: 0.1660 - val_accuracy: 0.9895\n",
            "Epoch 50/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0117 - accuracy: 0.9984 - val_loss: 0.2391 - val_accuracy: 0.9871\n",
            "Epoch 51/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0147 - accuracy: 0.9981 - val_loss: 0.2210 - val_accuracy: 0.9876\n",
            "Epoch 52/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0073 - accuracy: 0.9989 - val_loss: 0.1945 - val_accuracy: 0.9896\n",
            "Epoch 53/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0128 - accuracy: 0.9983 - val_loss: 0.2413 - val_accuracy: 0.9865\n",
            "Epoch 54/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0170 - accuracy: 0.9979 - val_loss: 0.1902 - val_accuracy: 0.9894\n",
            "Epoch 55/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0101 - accuracy: 0.9988 - val_loss: 0.1908 - val_accuracy: 0.9873\n",
            "Epoch 56/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0097 - accuracy: 0.9988 - val_loss: 0.2426 - val_accuracy: 0.9858\n",
            "Epoch 57/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0090 - accuracy: 0.9987 - val_loss: 0.1901 - val_accuracy: 0.9872\n",
            "Epoch 58/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0070 - accuracy: 0.9990 - val_loss: 0.1721 - val_accuracy: 0.9901\n",
            "Epoch 59/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0099 - accuracy: 0.9988 - val_loss: 0.2749 - val_accuracy: 0.9875\n",
            "Epoch 60/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0216 - accuracy: 0.9975 - val_loss: 0.2349 - val_accuracy: 0.9870\n",
            "Epoch 61/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0149 - accuracy: 0.9984 - val_loss: 0.1886 - val_accuracy: 0.9883\n",
            "Epoch 62/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0103 - accuracy: 0.9987 - val_loss: 0.1950 - val_accuracy: 0.9890\n",
            "Epoch 63/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0065 - accuracy: 0.9992 - val_loss: 0.1896 - val_accuracy: 0.9886\n",
            "Epoch 64/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0144 - accuracy: 0.9984 - val_loss: 0.2371 - val_accuracy: 0.9883\n",
            "Epoch 65/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0155 - accuracy: 0.9982 - val_loss: 0.2284 - val_accuracy: 0.9872\n",
            "Epoch 66/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0115 - accuracy: 0.9985 - val_loss: 0.2178 - val_accuracy: 0.9895\n",
            "Epoch 67/100\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.0112 - accuracy: 0.9987 - val_loss: 0.2289 - val_accuracy: 0.9879\n",
            "Epoch 68/100\n",
            "708/750 [===========================>..] - ETA: 0s - loss: 0.0191 - accuracy: 0.9979"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3470gboCzg1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b6c05ae2-8095-46b1-cb70-c50c4df0585e"
      },
      "source": [
        "print(history.history.keys())"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}